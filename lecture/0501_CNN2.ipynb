{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 패딩\n",
    "+ 데이터 확장하여 경계값 처리\n",
    "+ constant : 양쪽으로 상수 붙임\n",
    "+ reflect : 가운데 인덱스 값을 기준으로 반사\n",
    "+ symmetric : 양쪽 끝 값 기준 반사\n",
    "\n",
    "+ 1차원 데이터 패딩\n",
    "+ 2차원 데이터 패딩"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:43:22.695409Z",
     "end_time": "2023-05-01T14:43:31.806507Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1차원 패딩\n",
    "+ Reflect\n",
    "    + last digit before the padding (경계 digit 제외하고 반사)\n",
    "+ Symmetric\n",
    "    + the boundary number first (경계 포함 반사)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:45:11.921361Z",
     "end_time": "2023-05-01T14:45:11.934326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B= [0. 0. 1. 2. 3. 4. 5. 0. 0.]\n",
      "C= [3. 2. 1. 2. 3. 4. 5. 4. 3.]\n",
      "D= [2. 1. 1. 2. 3. 4. 5. 5. 4.]\n"
     ]
    }
   ],
   "source": [
    "#36_01\n",
    "#1: crate a 1D input data\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "\n",
    "#2\n",
    "p = 2\n",
    "paddings = np.array([[p, p]])\n",
    "\n",
    "#3\n",
    "B = tf.pad(A, paddings, \"constant\") # 고정값으로 채움 (default 0)\n",
    "C = tf.pad(A, paddings, \"reflect\") # 중앙값 기준 반사\n",
    "D = tf.pad(A, paddings, \"symmetric\") # 양쪽 끝 기준 반사\n",
    "print(\"B=\", B.numpy())\n",
    "print(\"C=\", C.numpy())\n",
    "print(\"D=\", D.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#36_02\n",
    "#1:\n",
    "def pad1d_infor(steps, kernel_size=2, strides=1,\n",
    "                  dilation_rate=1, padding= 'valid'):\n",
    "    k = (kernel_size-1)*dilation_rate + 1\n",
    "    if padding == 'valid':\n",
    "        new_steps = int(np.ceil((steps - k + 1) / strides))\n",
    "        pad_left, pad_right=(0, 0)\n",
    "\n",
    "    else: # 'same', 'casual'\n",
    "        new_steps = int(np.ceil(steps/strides))\n",
    "        pad_width = max((new_steps  - 1) * strides + k - steps, 0)\n",
    "\n",
    "        if padding == 'same':\n",
    "            pad_left  = pad_width//2\n",
    "            pad_right = pad_width - pad_left\n",
    "        if padding =='casual':\n",
    "            pad_left  = pad_width\n",
    "            pad_right = 0\n",
    "    return k, new_steps, (pad_left, pad_right)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:50:52.285733Z",
     "end_time": "2023-05-01T14:50:52.298698Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#2: crate a 1D input data\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "length = A.shape[0] #len(len), 5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:51:38.612250Z",
     "end_time": "2023-05-01T14:51:38.618233Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "new_k, new_steps, pads= pad1d_infor(steps=length, kernel_size=2, strides=2, padding= 'same')\n",
    "print(\"new_k ={}, new_steps={}, pads={}\".format(new_k,new_steps,pads))\n",
    "B1 = tf.pad(A, paddings=np.array([pads]))\n",
    "print(\"B1=\", B1.numpy())\n",
    "```\n",
    "+ B1= [1. 2. 3. 4. 5. 0.]\n",
    "\n",
    "[1,    kernal_size = 2, strides = 2\n",
    "2,          => (1,2), (3,4), (5,0) : new_steps : 3\n",
    "3,\n",
    "4,\n",
    "5]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_k =2, new_steps=3, pads=(0, 1)\n",
      "B1= [1. 2. 3. 4. 5. 0.]\n",
      "new_k =4, new_steps=2, pads=(1, 1)\n",
      "B2= [0. 1. 2. 3. 4. 5. 0.]\n"
     ]
    }
   ],
   "source": [
    "#3: padding in MaxPool1D [step37_02]\n",
    "#3-1:\n",
    "new_k, new_steps, pads= pad1d_infor(steps=length, kernel_size=2,\n",
    "                                      strides=2, padding= 'same')\n",
    "print(\"new_k ={}, new_steps={}, pads={}\".format(new_k,new_steps,pads))\n",
    "B1 = tf.pad(A, paddings=np.array([pads]))\n",
    "print(\"B1=\", B1.numpy())\n",
    "\n",
    "#3-2:\n",
    "new_k, new_steps, pads= pad1d_infor(steps=length, kernel_size=4,\n",
    "                                      strides=3, padding= 'same')\n",
    "print(\"new_k ={}, new_steps={}, pads={}\".format(new_k,new_steps,pads))\n",
    "B2 = tf.pad(A, paddings=np.array([pads]))\n",
    "print(\"B2=\", B2.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:51:40.353885Z",
     "end_time": "2023-05-01T14:51:40.373832Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_k =3, new_steps=5, pads=(1, 1)\n",
      "B3= [0. 1. 2. 3. 4. 5. 0.]\n",
      "new_k =3, new_steps=3, pads=(1, 1)\n",
      "B4= [0. 1. 2. 3. 4. 5. 0.]\n",
      "new_k =3, new_steps=5, pads=(2, 0)\n",
      "B5= [0. 0. 1. 2. 3. 4. 5.]\n",
      "new_k =5, new_steps=5, pads=(2, 2)\n",
      "B6= [0. 0. 1. 2. 3. 4. 5. 0. 0.]\n",
      "new_k =5, new_steps=5, pads=(4, 0)\n",
      "B7= [0. 0. 0. 0. 1. 2. 3. 4. 5.]\n",
      "new_k =7, new_steps=5, pads=(6, 0)\n",
      "B8= [0. 0. 0. 0. 0. 0. 1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "#4: padding in Conv1D\n",
    "#4-1:\n",
    "new_k, new_steps, pads= pad1d_infor(steps=length, kernel_size=3,\n",
    "                                      padding= 'same')\n",
    "print(\"new_k ={}, new_steps={}, pads={}\".format(new_k,new_steps,pads))\n",
    "B3 = tf.pad(A, paddings=np.array([pads]))\n",
    "print(\"B3=\", B3.numpy())\n",
    "\n",
    "#4-2:\n",
    "new_k, new_steps, pads= pad1d_infor(steps=length, kernel_size=3,\n",
    "                                      strides=2, padding= 'same')\n",
    "print(\"new_k ={}, new_steps={}, pads={}\".format(new_k,new_steps,pads))\n",
    "B4 = tf.pad(A, paddings=np.array([pads]))\n",
    "print(\"B4=\", B4.numpy())\n",
    "\n",
    "#4-3:\n",
    "new_k, new_steps, pads= pad1d_infor(steps=length, kernel_size=3,\n",
    "                                      dilation_rate=1, padding= 'casual')\n",
    "print(\"new_k ={}, new_steps={}, pads={}\".format(new_k,new_steps,pads))\n",
    "B5 = tf.pad(A, paddings=np.array([pads]))\n",
    "print(\"B5=\", B5.numpy())\n",
    "\n",
    "#4-4:\n",
    "new_k, new_steps, pads= pad1d_infor(steps=length, kernel_size=3,\n",
    "                                      dilation_rate=2, padding= 'same')\n",
    "print(\"new_k ={}, new_steps={}, pads={}\".format(new_k,new_steps,pads))\n",
    "B6 = tf.pad(A, paddings=np.array([pads]))\n",
    "print(\"B6=\", B6.numpy())\n",
    "\n",
    "#4-5:\n",
    "new_k, new_steps, pads= pad1d_infor(steps=length, kernel_size=3,\n",
    "                                      dilation_rate=2, padding= 'casual')\n",
    "print(\"new_k ={}, new_steps={}, pads={}\".format(new_k,new_steps,pads))\n",
    "B7 = tf.pad(A, paddings=np.array([pads]))\n",
    "print(\"B7=\", B7.numpy())\n",
    "\n",
    "#4-6:\n",
    "new_k, new_steps, pads= pad1d_infor(steps=length, kernel_size=3,\n",
    "                                      dilation_rate=3, padding= 'casual')\n",
    "print(\"new_k ={}, new_steps={}, pads={}\".format(new_k,new_steps,pads))\n",
    "B8 = tf.pad(A, paddings=np.array([pads]))\n",
    "print(\"B8=\", B8.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:58:03.278729Z",
     "end_time": "2023-05-01T14:58:03.293714Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2차원 패딩"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B= [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 2. 3. 0. 0.]\n",
      " [0. 0. 4. 5. 6. 0. 0.]\n",
      " [0. 0. 7. 8. 9. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "C= [[6. 5. 4. 5. 6. 5. 4.]\n",
      " [3. 2. 1. 2. 3. 2. 1.]\n",
      " [6. 5. 4. 5. 6. 5. 4.]\n",
      " [9. 8. 7. 8. 9. 8. 7.]\n",
      " [6. 5. 4. 5. 6. 5. 4.]]\n",
      "D= [[2. 1. 1. 2. 3. 3. 2.]\n",
      " [2. 1. 1. 2. 3. 3. 2.]\n",
      " [5. 4. 4. 5. 6. 6. 5.]\n",
      " [8. 7. 7. 8. 9. 9. 8.]\n",
      " [8. 7. 7. 8. 9. 9. 8.]]\n"
     ]
    }
   ],
   "source": [
    "#36_03\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#1: crate a 2D input data\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]]).astype('float32')\n",
    "#2\n",
    "pads = np.array([[1, 1], #2차원 행의 --, ++\n",
    "                     [2, 2]]) #2차원 열의 --. ++\n",
    "#3\n",
    "B = tf.pad(A, pads, \"constant\")\n",
    "C = tf.pad(A, pads, \"reflect\") # 바운더리 제외 반사\n",
    "D = tf.pad(A, pads, \"symmetric\") # 바운더리 기준 반사\n",
    "print(\"B=\", B.numpy())\n",
    "print(\"C=\", C.numpy())\n",
    "print(\"D=\", D.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:58:04.433135Z",
     "end_time": "2023-05-01T14:58:04.462057Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#36_04\n",
    "#1\n",
    "def pad2d_infor(input_shape, kernel_size=(2,2), strides=(1,1),\n",
    "                    dilation_rate=(1,1), padding= 'valid'):\n",
    "    rows, cols = input_shape\n",
    "    kH = (kernel_size[0]-1)*dilation_rate[0] + 1\n",
    "    kW = (kernel_size[1]-1)*dilation_rate[1] + 1\n",
    "\n",
    "    if padding == 'valid':\n",
    "        new_rows = int(np.ceil((input_shape[0]-kH+1)/strides[0]))\n",
    "        new_cols = int(np.ceil((input_shape[1]-kW+1)/strides[1]))\n",
    "        pad_left, pad_right, pad_top, pad_bottom=(0, 0, 0, 0)\n",
    "\n",
    "    else: # 'same'\n",
    "        new_rows = int(np.ceil(input_shape[0]/strides[0]))\n",
    "        new_cols = int(np.ceil(input_shape[1]/strides[1]))\n",
    "\n",
    "        pad_height = max((new_rows-1)*strides[0] + kH - input_shape[0], 0)\n",
    "        pad_width  = max((new_cols-1)*strides[1] + kW - input_shape[1], 0)\n",
    "\n",
    "        pad_top    = pad_height//2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left  = pad_width//2\n",
    "        pad_right = pad_width - pad_left\n",
    "    return (kH,kW),(new_rows,new_cols),[[pad_left,pad_right],[pad_top,pad_bottom]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T15:02:18.866674Z",
     "end_time": "2023-05-01T15:02:18.876647Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_k =(2, 2), new_shape=(2, 2), pads=[[0, 0], [0, 0]]\n",
      "B1= [[1. 2. 3. 4. 5.]\n",
      " [4. 3. 2. 1. 0.]\n",
      " [5. 6. 7. 8. 9.]\n",
      " [4. 3. 2. 1. 0.]\n",
      " [0. 1. 2. 3. 4.]]\n",
      "new_k =(2, 2), new_shape=(3, 3), pads=[[0, 1], [0, 1]]\n",
      "B2= [[1. 2. 3. 4. 5. 0.]\n",
      " [4. 3. 2. 1. 0. 0.]\n",
      " [5. 6. 7. 8. 9. 0.]\n",
      " [4. 3. 2. 1. 0. 0.]\n",
      " [0. 1. 2. 3. 4. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#2: crate a 2D input data\n",
    "A = np.array([[1, 2, 3, 4, 5],\n",
    "              [4, 3, 2, 1, 0],\n",
    "              [5, 6, 7, 8, 9],\n",
    "              [4, 3, 2, 1, 0],\n",
    "              [0, 1, 2, 3, 4]],dtype='float32')\n",
    "\n",
    "#3: padding in 2D\n",
    "#3-1:\n",
    "new_k, new_shape, pads= pad2d_infor(input_shape=A.shape,\n",
    "                                      kernel_size=(2,2), strides=(2,2), padding= 'valid')\n",
    "print(\"new_k ={}, new_shape={}, pads={}\".format(new_k, new_shape, pads))\n",
    "B1 = tf.pad(A, paddings=np.array(pads))\n",
    "print(\"B1=\", B1.numpy())\n",
    "\n",
    "#3-2:\n",
    "new_k, new_shape, pads= pad2d_infor(input_shape=A.shape,\n",
    "                         kernel_size=(2,2), strides=(2,2), padding= 'same')\n",
    "print(\"new_k ={}, new_shape={}, pads={}\".format(new_k, new_shape, pads))\n",
    "B2 = tf.pad(A, paddings=np.array(pads))\n",
    "print(\"B2=\", B2.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T15:30:00.690982Z",
     "end_time": "2023-05-01T15:30:00.703947Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A [1. 2. 3. 4. 5.]\n",
      "reshape: A [[[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]] (1, 5, 1)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding1d_5 (ZeroPaddi  (None, 8, 1)             0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "type(output) = <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "output.numpy()= [[[0.]\n",
      "  [1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]\n",
      "  [0.]\n",
      "  [0.]]]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000297EA4052D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "type(output2) = <class 'numpy.ndarray'>\n",
      "output2= [[[0.]\n",
      "  [1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]\n",
      "  [0.]\n",
      "  [0.]]]\n"
     ]
    }
   ],
   "source": [
    "#36_05\n",
    "#1: crate a 1D input data with 3-channels\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "print('A', A)\n",
    "A = np.reshape(A, (1, -1, 1)) # (batch, steps, channels)\n",
    "print('reshape: A', A, A.shape)\n",
    "\n",
    "\n",
    "#2: build a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=A.shape[1:]))  # shape=(5, 1)\n",
    "model.add(tf.keras.layers.ZeroPadding1D(padding=(1, 2)))\n",
    "model.summary()\n",
    "\n",
    "#3: apply A to model\n",
    "output = model(A)\n",
    "print(\"type(output) =\", type(output))\n",
    "print(\"output.numpy()=\", output.numpy())\n",
    "\n",
    "#4: apply A to model\n",
    "output2 = model.predict(A)\n",
    "print(\"type(output2) =\", type(output2))\n",
    "print(\"output2=\", output2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T15:39:04.748270Z",
     "end_time": "2023-05-01T15:39:04.840024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.]\n",
      "   [2.]\n",
      "   [3.]]\n",
      "\n",
      "  [[4.]\n",
      "   [5.]\n",
      "   [6.]]\n",
      "\n",
      "  [[7.]\n",
      "   [8.]\n",
      "   [9.]]]] (1, 3, 3, 1)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d_2 (ZeroPaddi  (None, 5, 7, 1)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "output.shape= (1, 5, 7, 1)\n",
      "output.numpy()= [[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [2.]\n",
      "   [3.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [4.]\n",
      "   [5.]\n",
      "   [6.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [7.]\n",
      "   [8.]\n",
      "   [9.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "output2.shape= (1, 5, 7, 1)\n",
      "output2= [[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [2.]\n",
      "   [3.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [4.]\n",
      "   [5.]\n",
      "   [6.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [7.]\n",
      "   [8.]\n",
      "   [9.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n"
     ]
    }
   ],
   "source": [
    "#36_06\n",
    "#1: crate a 2D input data\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]]).astype('float32')\n",
    "A = A.reshape(-1, 3, 3, 1)  # (batch, rows, cols, channels)\n",
    "print(A, A.shape)\n",
    "\n",
    "#2: build a model\n",
    "pads = np.array([[1, 1],  # rows: (left, right) padding\n",
    "                [2, 2]])  # cols: (top, bottom) padding\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=A.shape[1:]))  # (3,3,1)\n",
    "model.add(tf.keras.layers.ZeroPadding2D(padding=pads))\n",
    "model.summary()\n",
    "\n",
    "#3: apply A to model\n",
    "output = model(A)\n",
    "print(\"output.shape=\", output.shape) # 패딩 추가 되어서 (1, 5, 7, 1)\n",
    "print(\"output.numpy()=\", output.numpy())\n",
    "\n",
    "#4: apply A to model\n",
    "output2 = model.predict(A)\n",
    "print(\"output2.shape=\", output2.shape)\n",
    "print(\"output2=\", output2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T15:49:41.801441Z",
     "end_time": "2023-05-01T15:49:41.872251Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1차원 풀링\n",
    "+ 여러 개의 값을 하나의 값으로 다운 샘플링\n",
    "+ MaxPooling1D\n",
    "+ AveragePooling1D\n",
    "+ GlobalMaxPooling1D\n",
    "+ GlobalAveragePooling1D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A= [1. 2. 3. 4. 5.] (5,)\n",
      "output_size =  2\n"
     ]
    }
   ],
   "source": [
    "#37_01 (padding = 'valid')\n",
    "#1: GPU 메모리할당오류, [그림 2.9] 참조\n",
    "#ref:https://www.tensorflow.org/guide/gpu\n",
    "\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    for gpu in gpus:\n",
    "#        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "#else:\n",
    "#    print(\"No GPU found\")\n",
    "\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "\n",
    "#2\n",
    "# crate a 1D input data\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "\n",
    "#3: calculate output size in padding = \"valid\"\n",
    "k = 2           # pool_size, kernel_size\n",
    "s = 2           # slides\n",
    "n = len(A)      # input_size (=steps)\n",
    "output_size= int(np.ceil((n - k + 1) / s))\n",
    "print(\"A=\", A, A.shape)\n",
    "print(\"output_size = \", output_size)      # len(B)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T15:58:12.405868Z",
     "end_time": "2023-05-01T15:58:12.420828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " max_pooling1d_4 (MaxPooling  (None, 2, 1)             0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "output= [[[2.]\n",
      "  [4.]]] (1, 2, 1)\n",
      "B= [2. 4.] (2,)\n"
     ]
    }
   ],
   "source": [
    "#4: build a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape = (5, 1)))\n",
    "model.add(tf.keras.layers.MaxPool1D())               # k = 2, s = 2\n",
    "##model.add(tf.keras.layers.MaxPool1D(strides = 1) ) # k = 2, s = 1\n",
    "##model.add(tf.keras.layers.Flatten())      # (batch, downsampled_steps * channels)\n",
    "model.summary()\n",
    "\n",
    "#5: apply A to model\n",
    "A = np.reshape(A, (1, 5, 1))     # (batch, steps, channels)\n",
    "output = model.predict(A)        # (batch, downsampled_steps, channels)\n",
    "\n",
    "print(\"output=\", output, output.shape)\n",
    "B = output.flatten()\n",
    "print(\"B=\", B, B.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T15:58:21.142193Z",
     "end_time": "2023-05-01T15:58:21.218018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A= [1. 2. 3. 4. 5.] (5,)\n",
      "output_size =  4\n"
     ]
    }
   ],
   "source": [
    "#2-1 k, s 변경\n",
    "# crate a 1D input data\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "\n",
    "#3: calculate output size in padding = \"valid\"\n",
    "k = 2           # pool_size, kernel_size\n",
    "s = 1           # slides\n",
    "n = len(A)      # input_size (=steps)\n",
    "output_size= int(np.ceil((n - k + 1) / s))\n",
    "print(\"A=\", A, A.shape)\n",
    "print(\"output_size = \", output_size)      # len(B)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T16:00:53.337751Z",
     "end_time": "2023-05-01T16:00:53.348721Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " max_pooling1d_6 (MaxPooling  (None, 4, 1)             0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "output= [[[2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]] (1, 4, 1)\n",
      "B= [2. 3. 4. 5.] (4,)\n"
     ]
    }
   ],
   "source": [
    "#4: build a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape = (5, 1)))\n",
    "# model.add(tf.keras.layers.MaxPool1D())               # k = 2, s = 2\n",
    "model.add(tf.keras.layers.MaxPool1D(strides = 1) ) # k = 2, s = 1\n",
    "#model.add(tf.keras.layers.Flatten())      # (batch, downsampled_steps * channels)\n",
    "model.summary()\n",
    "\n",
    "#5: apply A to model\n",
    "A = np.reshape(A, (1, 5, 1))     # (batch, steps, channels)\n",
    "output = model.predict(A)        # (batch, downsampled_steps, channels)\n",
    "\n",
    "print(\"output=\", output, output.shape)\n",
    "B = output.flatten()\n",
    "print(\"B=\", B, B.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T16:02:06.946680Z",
     "end_time": "2023-05-01T16:02:07.016493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_steps =  3\n",
      "pad_left = 0, pad_right=1\n",
      "B= tf.Tensor([1. 2. 3. 4. 5. 5.], shape=(6,), dtype=float32)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " max_pooling1d_7 (MaxPooling  (None, 3, 1)             0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "C= [2. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "#37_02 (MaxPool1D, \"padding=same\")\n",
    "#1\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    for gpu in gpus:\n",
    "#        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "#else:\n",
    "#    print(\"No GPU found\")\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "#2: crate a 1D input data\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "\n",
    "#3: calculate padding and output size(new_steps)\n",
    "k = 2      # pool_size, kernel_size\n",
    "s = 2      # slides\n",
    "n = len(A) # input_size\n",
    "\n",
    "# the same as pad1d_infor(padding=\"same\")\n",
    "new_steps = int(np.ceil(n/s))\n",
    "print(\"new_steps = \", new_steps)\n",
    "\n",
    "pad_width\t= max((new_steps - 1) * s + k - n, 0)\n",
    "pad_left\t= pad_width // 2\n",
    "pad_right\t= pad_width - pad_left\n",
    "print(\"pad_left = %s, pad_right=%s\"%(pad_left, pad_right))\n",
    "\n",
    "paddings = np.array([[pad_left, pad_right]])\n",
    "B = tf.pad(A, paddings, \"symmetric\")\n",
    "print(\"B=\", B)\n",
    "\n",
    "#4: build a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape = (5, 1)))\n",
    "model.add(tf.keras.layers.MaxPool1D(pool_size = k, strides =s, padding=\"same\"))\n",
    "model.summary()\n",
    "\n",
    "#5: apply A to model\n",
    "A = np.reshape(A, (1, 5, 1)) # (batch, steps, channels)\n",
    "output = model.predict(A) # (batch, downsampled_steps, channels)\n",
    "C = output.flatten()\n",
    "print(\"C=\", C)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:57.422124Z",
     "end_time": "2023-05-01T16:19:57.494927Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_steps =  2\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " average_pooling1d (AverageP  (None, 2, 1)             0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "B= [1.5 3.5]\n"
     ]
    }
   ],
   "source": [
    "#37_03 (AveragePool1D, padding='valid')\n",
    "#1\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#if gpus:\n",
    "#    for gpu in gpus:\n",
    "#        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "#else:\n",
    "#    print(\"No GPU found\")\n",
    "#2: crate a 1D input data\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "\n",
    "#3: calculate output size in padding=\"valid\"\n",
    "k = 2      # pool_size, kernel_size\n",
    "s = 2      # slides\n",
    "n = len(A) # input_size\n",
    "# the same as pad1d_infor(padding=\"valid\")\n",
    "new_steps= int(np.ceil((n - k + 1) / s))\n",
    "print(\"new_steps = \", new_steps) # len(B)\n",
    "\n",
    "#4: build a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(5, 1)))\n",
    "model.add(tf.keras.layers.AveragePooling1D(pool_size=k, strides =s))\n",
    "model.summary()\n",
    "\n",
    "#5: apply A to model\n",
    "A = np.reshape(A, (1, 5, 1)) # (batch, steps, channels)\n",
    "output = model.predict(A)    # (batch, downsampled_steps, channels)\n",
    "B = output.flatten()\n",
    "print(\"B=\", B)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T16:27:10.594512Z",
     "end_time": "2023-05-01T16:27:10.959773Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_steps  =  3\n",
      "pad_left = 0, pad_right=1\n",
      "B= tf.Tensor([1. 2. 3. 4. 5. 0.], shape=(6,), dtype=float32)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " average_pooling1d_2 (Averag  (None, 3, 1)             0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "C= [1.5 3.5 5. ]\n"
     ]
    }
   ],
   "source": [
    "#37_04 (AveragePool1D, padding='same')\n",
    "#1\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#if gpus:\n",
    "#    for gpu in gpus:\n",
    "#        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "#else:\n",
    "#    print(\"No GPU found\")\n",
    "#2: crate a 1D input data\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "\n",
    "#3: calculate padding and output size(new_steps)\n",
    "k = 2      # pool_size, kernel_size\n",
    "s = 2      # slides\n",
    "n = len(A) # input_size\n",
    "\n",
    "# the same as pad1d_infor(padding=\"same\")\n",
    "new_steps = int(np.ceil(n/s))\n",
    "print(\"new_steps  = \", new_steps ) # len(C)\n",
    "\n",
    "pad_width\t= max((new_steps - 1) * s + k - n, 0)\n",
    "pad_left\t= pad_width // 2\n",
    "pad_right\t= pad_width - pad_left\n",
    "print(\"pad_left = %s, pad_right=%s\"%(pad_left, pad_right))\n",
    "\n",
    "paddings = np.array([[pad_left, pad_right]])\n",
    "B = tf.pad(A, paddings) # 0-padding, but mode don't care, not used padding values\n",
    "print(\"B=\", B)\n",
    "\n",
    "#4: build a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape = (5, 1)))\n",
    "model.add(tf.keras.layers.AveragePooling1D(pool_size = k, strides =s, padding=\"same\"))\n",
    "model.summary()\n",
    "\n",
    "#5: apply A to model\n",
    "A = np.reshape(A, (1, 5, 1)) # (batch, steps, channels)\n",
    "output = model.predict(A)    # (batch, downsampled_steps, channels)\n",
    "C = output.flatten()\n",
    "print(\"C=\", C)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T16:33:19.012246Z",
     "end_time": "2023-05-01T16:33:19.088043Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "B= [[[2. 2. 2.]\n",
      "  [4. 4. 4.]]]\n",
      "B[:,:,0]= [[2. 4.]]\n",
      "B[:,:,1]= [[2. 4.]]\n",
      "B[:,:,2]= [[2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "#37_05 (1차원 다채널 데이터 풀링)\n",
    "#1\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#if gpus:\n",
    "#    for gpu in gpus:\n",
    "#        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "#else:\n",
    "#    print(\"No GPU found\")\n",
    "#2: crate a 1D input data with 3-channels\n",
    "A = np.array([[1, 1, 1],\n",
    "              [2, 2, 2],\n",
    "              [3, 3, 3],\n",
    "              [4, 4, 4],\n",
    "              [5, 5, 5]], dtype='float32')\n",
    "A = np.expand_dims(A, axis=0) # shape = ([1, 5, 3])\n",
    "\n",
    "#3: build a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape = (5, 3)))\n",
    "model.add(tf.keras.layers.MaxPool1D()) #pool_size = 2, strides =2 padding='valid'\n",
    "##model.add(tf.keras.layers.AveragePooling1D())\n",
    "##model.add(tf.keras.layers.MaxPool1D(padding='same')\n",
    "##model.add(tf.keras.layers.AveragePooling1D(padding='same'))\n",
    "##model.summary()\n",
    "\n",
    "#4: apply A to model\n",
    "B = model.predict(A) # (batch, downsampled_steps, channels)\n",
    "print(\"B=\", B)\n",
    "print(\"B[:,:,0]=\", B[:,:,0]) # 0-channel R\n",
    "print(\"B[:,:,1]=\", B[:,:,1]) # 1-channel G\n",
    "print(\"B[:,:,2]=\", B[:,:,2]) # 2-channel B\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T16:33:49.313176Z",
     "end_time": "2023-05-01T16:33:49.376007Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " global_max_pooling1d (Globa  (None, 3)                0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "output= [[5. 4. 3.]]\n"
     ]
    }
   ],
   "source": [
    "#37_06 GlobalMaxPooling1D\n",
    "#1\n",
    "##gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "##tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "#2: crate a 1D input data with 3-channels\n",
    "A = np.array([[1, 0, 0],\n",
    "              [2, 4, 0],\n",
    "              [3, 3, 3],\n",
    "              [4, 2, 2],\n",
    "              [5, 1, 1]], dtype='float32')\n",
    "A = np.expand_dims(A, axis=0) # (batch, steps, channels)= ([1, 5, 3])\n",
    "\n",
    "#3: build a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(5, 3)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "# model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "model.summary()\n",
    "\n",
    "#4: apply A to model\n",
    "output = model.predict(A)   # (batch, channels) = (1, 3)\n",
    "print(\"output=\", output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T16:41:08.523550Z",
     "end_time": "2023-05-01T16:41:08.616302Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1차원 합성곱\n",
    "+ 커널(가중치)과 내적으로 계산"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 3, 1)              3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "B= [ 6.  9. 12.]\n"
     ]
    }
   ],
   "source": [
    "#38_01\n",
    "#1\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#if gpus:\n",
    "#    for gpu in gpus:\n",
    "#        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "#else:\n",
    "#    print(\"No GPU found\")\n",
    "#2: crate a 1D input data\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "A = np.reshape(A, (1, 5, 1))  #  (batch, steps, channels)\n",
    "\n",
    "#3: build a model\n",
    "KERNEL_SIZE = 3\n",
    "STRIDE      = 1\n",
    "PADDING  = 'valid'  # 'same’\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "##model.add(tf.keras.layers.Input(shape = A.shape[1:])) # (5, 1)\n",
    "##model.add(tf.keras.layers.Conv1D(filters=1,\n",
    "##                                 kernel_size = KERNEL_SIZE,\n",
    "##                                 strides= STRIDE,\n",
    "##                                 padding= PADDING,\n",
    "##                                 use_bias=False,\n",
    "##                                 kernel_initializer=tf.constant_initializer(1),\n",
    "##                                 ))\n",
    "model.add(tf.keras.layers.Conv1D(filters=1,\n",
    "                                 kernel_size = KERNEL_SIZE,\n",
    "                                 strides= STRIDE,\n",
    "                                 padding= PADDING,\n",
    "                                 use_bias=False,\n",
    "                                 kernel_initializer=tf.constant_initializer(1),\n",
    "                                 input_shape=A.shape[1:])) # (5, 1)\n",
    "model.summary()\n",
    "\n",
    "#4: apply A to model\n",
    "output = model.predict(A) # output.shape : (batch, new_steps, filters)\n",
    "B = output.flatten()       # B = tf.reshape(output,[-1]).numpy()\n",
    "print(\"B=\", B)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T17:16:22.732433Z",
     "end_time": "2023-05-01T17:16:22.998834Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### dilation_rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#38_02 (filter=1, dilation_rate=2, padding='casual')\n",
    "#1\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#if gpus:\n",
    "#    for gpu in gpus:\n",
    "#        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "#else:\n",
    "#    print(\"No GPU found\")\n",
    "#2: crate a 1D input data\n",
    "A = np.array([1, 2, 3, 4, 5]).astype('float32')\n",
    "A = np.reshape(A, (1, 5, 1)) # (batch, steps, channels)\n",
    "\n",
    "#3: build a model\n",
    "KERNEL_SIZE = 3\n",
    "DILATE = 1          # 1, 2, 3\n",
    "PADDING  = 'causal'  # 'valid' 'same’\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(filters=1,\n",
    "                                 kernel_size = KERNEL_SIZE,\n",
    "                                 strides= 1,\n",
    "                                 padding= PADDING,\n",
    "                                 dilation_rate=DILATE,\n",
    "                                 use_bias=False,\n",
    "                                 kernel_initializer=tf.constant_initializer(1),\n",
    "                                 input_shape=A.shape[1:])) # (5, 1)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.summary()\n",
    "\n",
    "#4: apply A to model\n",
    "B = model.predict(A)   # B.shape : (batch, new_steps*filters)\n",
    "print(\"B=\", B)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "model.trainable_variables= [<tf.Variable 'dense/kernel:0' shape=(5, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.]], dtype=float32)>]\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "output= [[15. 30.]\n",
      " [ 5. 10.]\n",
      " [ 6. 12.]]\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 1, 2)              10        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "model2.trainable_variables= [<tf.Variable 'conv1d_1/kernel:0' shape=(5, 1, 2) dtype=float32, numpy=\n",
      "array([[[1., 2.]],\n",
      "\n",
      "       [[1., 2.]],\n",
      "\n",
      "       [[1., 2.]],\n",
      "\n",
      "       [[1., 2.]],\n",
      "\n",
      "       [[1., 2.]]], dtype=float32)>]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "output2= [[15. 30.]\n",
      " [ 5. 10.]\n",
      " [ 6. 12.]]\n"
     ]
    }
   ],
   "source": [
    "#38_03 (Conv1D)\n",
    "#1\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#if gpus:\n",
    "#    for gpu in gpus:\n",
    "#        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "#else:\n",
    "#    print(\"No GPU found\")\n",
    "\n",
    "#2: crate a 1D input data\n",
    "A = np.array([[1, 2, 3, 4, 5],\n",
    "              [1, 1, 1, 1, 1],\n",
    "              [1, 2, 0, 1, 2]], dtype='float32') # batch = 3 (3개의 1차원 데이터)\n",
    "n = 2 # number of neurons in Dense, # of filters in Conv1D\n",
    "steps = A.shape[1] # length, 5\n",
    "\n",
    "#3: kernel initial values, shape: (5, 2)\n",
    "W = np.array([[1., 2.],\n",
    "              [1., 2.],\n",
    "              [1., 2.],\n",
    "              [1., 2.],\n",
    "              [1., 2.]], dtype=\"float\")\n",
    "\n",
    "#4: Dense with n units, input_dim = steps\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=steps ))\n",
    "model.add(tf.keras.layers.Dense(units=n, use_bias=False , # input_dim=steps,\n",
    "                                 kernel_initializer=tf.constant_initializer(W)))\n",
    "model.summary()\n",
    "print(\"model.trainable_variables=\", model.trainable_variables)\n",
    "\n",
    "# apply A to model\n",
    "##output = model(A)      # tensor, output.shape= (3, 2)\n",
    "output = model.predict(A) # numpy, output.shape= (3, 2)\n",
    "print(\"output=\", output)\n",
    "\n",
    "#5: Conv1D with n filters, kernel_size =steps, strides = 1, input shape=(steps,1)\n",
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.Input(shape=(steps,1)))\n",
    "model2.add(tf.keras.layers.Conv1D(filters = n, kernel_size = steps, use_bias=False,                                        kernel_initializer= tf.constant_initializer(W)))\n",
    "model2.add(tf.keras.layers.Flatten()) # output.shape : (batch, new_steps*filters)\n",
    "model2.summary()\n",
    "print(\"model2.trainable_variables=\", model2.trainable_variables)\n",
    "\n",
    "# apply A to model2\n",
    "A2 = np.expand_dims(A, axis=2) # tf.expand_dims(A, axis=2), shape = ([3, 5, 1])\n",
    "##print(\"A2 = \", A2)\n",
    "output2 = model2.predict(A2) # output2.shape= (3, 2)\n",
    "print(\"output2=\", output2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T17:28:52.646683Z",
     "end_time": "2023-05-01T17:28:53.126401Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 1, 2)              30        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "A =  [[[1. 1. 1.]\n",
      "  [2. 1. 2.]\n",
      "  [3. 1. 0.]\n",
      "  [4. 1. 1.]\n",
      "  [5. 1. 2.]]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "output= [[26. 52.]]\n"
     ]
    }
   ],
   "source": [
    "#38_04 (3채널 데이터)\n",
    "#2: crate a 1D input data\n",
    "A = np.array([[1, 1, 1],\n",
    "              [2, 1, 2],\n",
    "              [3, 1, 0],\n",
    "              [4, 1, 1],\n",
    "              [5, 1, 2]], dtype='float32')\n",
    "n = 2 # number of filters in Conv1D\n",
    "steps = 5 # A.shape[0], 5, length\n",
    "\n",
    "#3: kernel initial values, channels\n",
    "W0 = np.ones(shape=(5, 3), dtype='float32')\n",
    "W1 = np.full(shape=(5, 3), fill_value=2.0, dtype='float32')\n",
    "W = np.stack((W0, W1), axis=2) # (5, 3, 2)\n",
    "\n",
    "#4: Conv1D with n filters,  kernel_size =steps, strides = 1,\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(steps, 3)))\n",
    "model.add(tf.keras.layers.Conv1D(filters= n, kernel_size= steps, use_bias= False,\n",
    "                                 kernel_initializer= tf.constant_initializer(W)))\n",
    "model.add(tf.keras.layers.Flatten()) # output.shape : (batch, new_steps*filters)\n",
    "model.summary()\n",
    "\n",
    "#5: apply A to model\n",
    "A = np.expand_dims(A, axis=0) # tf.expand_dims(A, axis=0), shape = ([1, 5, 3])\n",
    "print(\"A = \", A)\n",
    "\n",
    "output = model.predict(A) # output.shape =(1, 2)\n",
    "print(\"output=\", output)\n",
    "\n",
    "##w = model.trainable_variables[0].numpy()\n",
    "##print(\"w[:,:,0]=\", w[:,:,0]) # W[:,:,0]\n",
    "##print(\"w[:,:,1]=\", w[:,:,1]) # W[:,:,1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T17:44:01.646358Z",
     "end_time": "2023-05-01T17:44:01.753072Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
